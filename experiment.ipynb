{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37c9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([9, 4, 0])\n",
    "embd = nn.Embedding(10+5+2, 3)\n",
    "embd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method1\n",
    "# x是同一个特征的不同level-index, 比如都是tokens, 三个index分别代表tokens[9], tokens[4], tokens[0], vocab_size=17. 那么x的onehot表示如下\n",
    "x_oh = nn.functional.one_hot(x, 17)\n",
    "x_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method2\n",
    "# x是不同特征的level-index, 比如分别代表user_id[9], item_id[4], content_id[0], level_size分别是(10, 5, 2). 那么x的onehot_concat表示如下\n",
    "torch.tensor([0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corresponding\n",
    "y = torch.tensor([9, 14, 15])\n",
    "nn.functional.one_hot(y, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46edc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee41a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([9, 4, 0])\n",
    "num_classes = torch.tensor([10, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([torch.zeros(1,), torch.cumsum(num_classes, dim=0)[:-1]], dim=0).type(num_classes.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f9692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_multifeatures(input_tensor, num_classes):\n",
    "    assert len(num_classes) == input_tensor.shape[-1], 'every feature must have its num_class'\n",
    "    assert torch.all(input_tensor < num_classes), 'index number exceeds or be equal to num_classes. Index number must be smaller than corresponding num_class'\n",
    "    offsets = torch.cat([torch.zeros(1,), torch.cumsum(num_classes, dim=0)[:-1]], dim=0).type(num_classes.dtype)\n",
    "    return (input_tensor + offsets).type(input_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0b5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[[9, 3, 4],\n",
    "                   [0, 1, 0],\n",
    "                   [7, 0, 0],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 1, 1]],\n",
    "                  [[9, 3, 4],\n",
    "                   [0, 1, 0],\n",
    "                   [7, 0, 0],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 1, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48c1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "class MultiIndexEmbedding(nn.Embedding):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, input: Tensor, num_classes: Tensor, flatten=True) -> Tensor:\n",
    "        input_ = offset_multifeatures(input, num_classes)\n",
    "        num_embeddings = int(num_classes.sum())\n",
    "        if self.num_embeddings != num_embeddings:\n",
    "            warnings.warn(f'arg num_embeddings must be the sum of number of classes of all features. num_embdggins={num_embeddings} set automatically')\n",
    "            self.num_embeddings = num_embeddings\n",
    "        embed_ = super(MultiIndexEmbedding, self).forward(input_)\n",
    "        if flatten:\n",
    "            return embed_.flatten(start_dim=-2)\n",
    "        else:\n",
    "            return embed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1644b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4871,  1.2604, -0.6868],\n",
       "          [-0.0262,  0.9785,  0.4463],\n",
       "          [ 1.4684,  0.3059, -0.2481]],\n",
       "\n",
       "         [[ 0.2354,  2.5292,  2.2188],\n",
       "          [ 0.1607,  0.8775, -1.2654],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.3228,  0.3680, -0.0678],\n",
       "          [ 0.8700,  0.4354, -0.1996],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.2354,  2.5292,  2.2188],\n",
       "          [ 0.8700,  0.4354, -0.1996],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.9199,  0.5815,  1.5986],\n",
       "          [ 0.1607,  0.8775, -1.2654],\n",
       "          [-0.5123, -0.7143, -1.2022]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4871,  1.2604, -0.6868],\n",
       "          [-0.0262,  0.9785,  0.4463],\n",
       "          [ 1.4684,  0.3059, -0.2481]],\n",
       "\n",
       "         [[ 0.2354,  2.5292,  2.2188],\n",
       "          [ 0.1607,  0.8775, -1.2654],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.3228,  0.3680, -0.0678],\n",
       "          [ 0.8700,  0.4354, -0.1996],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.2354,  2.5292,  2.2188],\n",
       "          [ 0.8700,  0.4354, -0.1996],\n",
       "          [-0.1132, -1.3775, -0.2470]],\n",
       "\n",
       "         [[ 0.9199,  0.5815,  1.5986],\n",
       "          [ 0.1607,  0.8775, -1.2654],\n",
       "          [-0.5123, -0.7143, -1.2022]]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = torch.tensor([10, 5, 6])\n",
    "embed = MultiIndexEmbedding(21, 3)\n",
    "embed(x, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "81b0bd1c56595d2e11429bb1af0ffa8a1550d993af8a59c01efaa46355771b1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
