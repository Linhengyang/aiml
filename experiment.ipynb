{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37c9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10a88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size, patch_size, num_hiddens, batch_size = 96, 16, 512, 4\n",
    "# x = torch.ones(batch_size, 3, img_size, img_size)\n",
    "# conv_layer = nn.LazyConv2d(num_hiddens, kernel_size=(patch_size, patch_size), stride=(patch_size, patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6682074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_layer(x).flatten(start_dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49069012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(16).reshape(4, 4).type(torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b636ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  4.],\n",
       "         [ 1.,  5.],\n",
       "         [ 2.,  6.],\n",
       "         [ 3.,  7.]],\n",
       "\n",
       "        [[ 8., 12.],\n",
       "         [ 9., 13.],\n",
       "         [10., 14.],\n",
       "         [11., 15.]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 展开维度、kernel size、stride\n",
    "a = x.unfold(0, 2, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db9d9498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.],\n",
       "          [ 4.,  5.]],\n",
       "\n",
       "         [[ 2.,  3.],\n",
       "          [ 6.,  7.]]],\n",
       "\n",
       "\n",
       "        [[[ 8.,  9.],\n",
       "          [12., 13.]],\n",
       "\n",
       "         [[10., 11.],\n",
       "          [14., 15.]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12f5768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.],\n",
       "         [ 4.,  5.]],\n",
       "\n",
       "        [[ 2.,  3.],\n",
       "         [ 6.,  7.]],\n",
       "\n",
       "        [[ 8.,  9.],\n",
       "         [12., 13.]],\n",
       "\n",
       "        [[10., 11.],\n",
       "         [14., 15.]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.unfold(1, 2, 2)\n",
    "b.reshape(4, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a0fa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_divide(img_batch, kernel_size):\n",
    "    # img_batch shape:(batch_size, n_channels, h, w)\n",
    "    h, w = img_batch.shape[2:]\n",
    "    k_h, k_w = kernel_size\n",
    "    pad_num_h, pad_num_w = 0 if h % k_h == 0 else k_h - h % k_h, 0 if w % k_w == 0 else k_w - w % k_w\n",
    "    pad_num_u = pad_num_h // 2\n",
    "    pad_num_d = pad_num_h - pad_num_u\n",
    "    pad_num_l = pad_num_w // 2\n",
    "    pad_num_r = pad_num_w - pad_num_l\n",
    "    return nn.functional.pad(img_batch, pad=(pad_num_l, pad_num_r, pad_num_u, pad_num_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c5dcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(img_batch, patch_size):\n",
    "    img_batch = pad_to_divide(img_batch, patch_size)\n",
    "    p_h, p_w = patch_size\n",
    "    # img_batch shape:(batch_size, num_channels, h, w)\n",
    "    batch_size, num_chnls, h, w = img_batch.shape\n",
    "    return img_batch.unfold(2, patch_size[0], patch_size[0]).unfold(3, patch_size[1], patch_size[1]).reshape(batch_size, num_chnls, -1,p_h, p_w).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32a0bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f53e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1, 2, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = patchify(x.unsqueeze(0).unsqueeze(0), (2,2))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05909c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "81b0bd1c56595d2e11429bb1af0ffa8a1550d993af8a59c01efaa46355771b1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
